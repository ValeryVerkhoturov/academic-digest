{
 "cells": [
  {
   "cell_type": "code",
   "id": "5b4f42410c124e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:27:19.587700Z",
     "start_time": "2025-10-12T14:27:19.584270Z"
    }
   },
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "46f89d0f66c8318f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:27:20.000252Z",
     "start_time": "2025-10-12T14:27:19.998064Z"
    }
   },
   "source": [
    "# https://huggingface.co/TechxGenus/Meta-Llama-3-70B-Instruct-GPTQ\n",
    "LLAMA3_BASE_URL = 'https://corellm.wb.ru/llama3/v1'\n",
    "LLAMA3_MODEL_NAME = 'Meta-Llama-3-70B-Instruct-GPTQ'\n",
    "\n",
    "\n",
    "DEEPSEEK_BASE_URL = 'https://corellm.wb.ru/deepseek/v1'\n",
    "DEEPSEEK_MODEL_NAME = 'DeepSeek-R1'\n",
    "\n",
    "\n",
    "QWEN25_32B_BASE_URL = 'https://corellm.wb.ru/qwen25-coder-14b-instruct/v1/'\n",
    "QWEN25_32B_MODEL_NAME = 'Qwen25-Coder-14B-Instruct'"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "d046a089b5b5e035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:27:20.425053Z",
     "start_time": "2025-10-12T14:27:20.423123Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "RWB_CORELLM_TOKEN = os.getenv(\"RWB_CORELLM_TOKEN\")\n",
    "SOURCE_ARTICLE_NAME = 'Exploring ChatGPT and its impact on society MA Haque, S Li'"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "f53d9fa61967b985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:27:21.369202Z",
     "start_time": "2025-10-12T14:27:21.333292Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('pdf_extracted_text.csv')"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "bd3be78ce6ebdb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:27:21.782661Z",
     "start_time": "2025-10-12T14:27:21.779429Z"
    }
   },
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "def process_pdf_with_llm(pdf_content, source_article_name, client, model_name, max_retries=1):\n",
    "    if not pdf_content or pd.isna(pdf_content) or pdf_content.strip() == \"\":\n",
    "        return \"No content to process\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": f\"You are a helpful assistant. User will give you article. Find article context which references to '{source_article_name}'. Write only text from article that mentions or references this source. If no references found, write 'No references found'.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": pdf_content,\n",
    "                    }\n",
    "                ],\n",
    "                model=model_name,\n",
    "                stream=False,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            response = chat_completion.choices[0].message.content\n",
    "            return response.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)  # Wait before retry\n",
    "            else:\n",
    "                return f\"Error after {max_retries} attempts: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "4fb346b6344fc83c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:56:16.045293Z",
     "start_time": "2025-10-12T14:35:14.748047Z"
    }
   },
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "base_url = DEEPSEEK_BASE_URL\n",
    "model_name = DEEPSEEK_MODEL_NAME\n",
    "digest_col_name = f\"{model_name}_digest\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=RWB_CORELLM_TOKEN,\n",
    "    base_url=base_url,\n",
    ")\n",
    "\n",
    "def process_row(args):\n",
    "    idx, pdf_content = args\n",
    "\n",
    "    digest = process_pdf_with_llm(\n",
    "        pdf_content=pdf_content,\n",
    "        source_article_name=SOURCE_ARTICLE_NAME,\n",
    "        client=client,\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    return idx, digest\n",
    "\n",
    "df[digest_col_name] = None\n",
    "\n",
    "non_null_mask = df['pdf_content'].notna() & (df['pdf_content'].str.strip() != '')\n",
    "rows_to_process = df[non_null_mask]\n",
    "\n",
    "print(f\"\\nProcessing {len(rows_to_process)} rows with non-null PDF content...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "args_list = [\n",
    "    (idx, row['pdf_content'])\n",
    "    for idx, row in rows_to_process.iterrows()\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(process_row, args): args for args in args_list}\n",
    "\n",
    "\n",
    "    with tqdm.tqdm(total=len(futures), desc=\"Processing PDFs' content\") as pbar:\n",
    "        for future in as_completed(futures):\n",
    "            idx, digest = future.result()\n",
    "            df.at[idx, digest_col_name] = digest\n",
    "            pbar.update(1)\n",
    "\n",
    "print(f\"Processing complete\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 30 rows with non-null PDF content...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  30%|███       | 9/30 [12:41<22:27, 64.16s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Error code: 400 - {'object': 'error', 'message': \"The input (248740 tokens) is longer than the model's context length (163840 tokens).\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
      "Attempt 2 failed: Error code: 400 - {'object': 'error', 'message': \"The input (248740 tokens) is longer than the model's context length (163840 tokens).\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  33%|███▎      | 10/30 [12:48<15:27, 46.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 3 failed: Error code: 400 - {'object': 'error', 'message': \"The input (248740 tokens) is longer than the model's context length (163840 tokens).\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 30/30 [21:01<00:00, 42.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "fb337cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:56:42.874337Z",
     "start_time": "2025-10-12T14:56:42.831846Z"
    }
   },
   "source": [
    "output_filename = 'pdf_extracted_text_with_digests.csv'\n",
    "df.to_csv(output_filename, index=False)\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "78dd0f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:57:53.489406Z",
     "start_time": "2025-10-12T14:57:53.485173Z"
    }
   },
   "source": [
    "print(\"DIGEST ANALYSIS for\", model_name)\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Total digests generated: {df[digest_col_name].notna().sum()}\")\n",
    "\n",
    "references_found = df[df[digest_col_name].str.contains('No references found', na=False)].shape[0]\n",
    "references_not_found = df[df[digest_col_name].notna() & ~df[digest_col_name].str.contains('No references found', na=False)].shape[0]\n",
    "\n",
    "print(f\"\\nReference Analysis:\")\n",
    "print(f\"References found: {references_not_found}\")\n",
    "print(f\"No references found: {references_found}\")\n",
    "print(f\"Success rate: {references_not_found/(references_not_found + references_found)*100:.1f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIGEST ANALYSIS for DeepSeek-R1\n",
      "============================================================\n",
      "Total digests generated: 30\n",
      "\n",
      "Reference Analysis:\n",
      "References found: 30\n",
      "No references found: 0\n",
      "Success rate: 100.0%\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63ff74b49d53af1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
