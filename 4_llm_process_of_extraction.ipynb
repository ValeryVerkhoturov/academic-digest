{
 "cells": [
  {
   "cell_type": "code",
   "id": "5b4f42410c124e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:18:31.065398Z",
     "start_time": "2025-10-12T14:18:31.055691Z"
    }
   },
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "46f89d0f66c8318f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:18:31.551197Z",
     "start_time": "2025-10-12T14:18:31.549042Z"
    }
   },
   "source": [
    "# https://huggingface.co/TechxGenus/Meta-Llama-3-70B-Instruct-GPTQ\n",
    "LLAMA3_BASE_URL = 'https://corellm.wb.ru/llama3/v1'\n",
    "LLAMA3_MODEL_NAME = 'Meta-Llama-3-70B-Instruct-GPTQ'\n",
    "\n",
    "\n",
    "DEEPSEEK_BASE_URL = 'https://corellm.wb.ru/deepseek/v1'\n",
    "DEEPSEEK_MODEL_NAME = 'DeepSeek-R1'\n",
    "\n",
    "\n",
    "QWEN25_32B_BASE_URL = 'https://corellm.wb.ru/qwen25-coder-14b-instruct/v1/'\n",
    "QWEN25_32B_MODEL_NAME = 'Qwen25-Coder-14B-Instruct'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d046a089b5b5e035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:18:32.124270Z",
     "start_time": "2025-10-12T14:18:32.122319Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "RWB_CORELLM_TOKEN = os.getenv(\"RWB_CORELLM_TOKEN\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "be9cd21af91827c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:18:33.088660Z",
     "start_time": "2025-10-12T14:18:33.087070Z"
    }
   },
   "source": [
    "SOURCE_ARTICLE_NAME = 'Exploring ChatGPT and its impact on society MA Haque, S Li'"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f53d9fa61967b985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:18:35.387438Z",
     "start_time": "2025-10-12T14:18:35.151772Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('pdf_extracted_text.csv')"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "bd3be78ce6ebdb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:00:10.780469Z",
     "start_time": "2025-10-12T14:00:10.756284Z"
    }
   },
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "def process_pdf_with_llm(pdf_content, source_article_name, client, model_name, max_retries=3):\n",
    "    if not pdf_content or pd.isna(pdf_content) or pdf_content.strip() == \"\":\n",
    "        return \"No content to process\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": f\"You are a helpful assistant. User will give you article. Find article context which references to '{source_article_name}'. Write only text from article that mentions or references this source. If no references found, write 'No references found'.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": pdf_content[:8000],  # Limit content to avoid token limits\n",
    "                    }\n",
    "                ],\n",
    "                model=model_name,\n",
    "                stream=False,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            response = chat_completion.choices[0].message.content\n",
    "            return response.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)  # Wait before retry\n",
    "            else:\n",
    "                return f\"Error after {max_retries} attempts: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "4fb346b6344fc83c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:10:33.052597Z",
     "start_time": "2025-10-12T14:04:32.852677Z"
    }
   },
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "base_url = DEEPSEEK_BASE_URL\n",
    "model_name = DEEPSEEK_MODEL_NAME\n",
    "digest_col_name = f\"{model_name}_digest\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=RWB_CORELLM_TOKEN,\n",
    "    base_url=base_url,\n",
    ")\n",
    "\n",
    "def process_row(args):\n",
    "    idx, pdf_content = args\n",
    "\n",
    "    digest = process_pdf_with_llm(\n",
    "        pdf_content=pdf_content,\n",
    "        source_article_name=SOURCE_ARTICLE_NAME,\n",
    "        client=client,\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    return idx, digest\n",
    "\n",
    "df[digest_col_name] = None\n",
    "\n",
    "non_null_mask = df['pdf_content'].notna() & (df['pdf_content'].str.strip() != '')\n",
    "rows_to_process = df[non_null_mask]\n",
    "\n",
    "print(f\"\\nProcessing {len(rows_to_process)} rows with non-null PDF content...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "args_list = [\n",
    "    (idx, row['pdf_content'])\n",
    "    for idx, row in rows_to_process.iterrows()\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(process_row, args): args for args in args_list}\n",
    "\n",
    "\n",
    "    with tqdm.tqdm(total=len(futures), desc=\"Processing PDFs\") as pbar:\n",
    "        for future in as_completed(futures):\n",
    "            idx, digest = future.result()\n",
    "            df.at[idx, digest_col_name] = digest\n",
    "            pbar.update(1)\n",
    "\n",
    "print(f\"\\nProcessing complete\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 30 rows with non-null PDF content...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   3%|â–Ž         | 1/30 [00:29<14:17, 29.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 8: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   7%|â–‹         | 2/30 [00:42<09:08, 19.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 7: Digest length: 508 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  10%|â–ˆ         | 3/30 [00:43<05:03, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 9: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  13%|â–ˆâ–Ž        | 4/30 [00:46<03:29,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 3: Digest length: 579 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  17%|â–ˆâ–‹        | 5/30 [00:47<02:20,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 0: Digest length: 305 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  20%|â–ˆâ–ˆ        | 6/30 [00:52<02:08,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 4: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [01:08<03:19,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 1: Digest length: 184 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  27%|â–ˆâ–ˆâ–‹       | 8/30 [01:16<03:08,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 2: Digest length: 651 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [01:19<02:23,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 10: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [01:26<02:18,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 12: Digest length: 395 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [01:39<02:43,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 13: Digest length: 747 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [01:47<02:34,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 11: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [01:48<01:46,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 17: Digest length: 713 characters\n",
      "\n",
      "Row 15: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [01:52<01:04,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 6: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [02:01<01:17,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 16: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [02:13<01:33,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 19: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [02:31<02:00, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 20: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [02:38<01:41,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 25: Digest length: 217 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [02:40<01:10,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 22: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [02:44<00:55,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 23: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [02:47<00:41,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 24: Digest length: 743 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [02:55<00:43,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 27: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [03:06<00:44,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 28: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [03:07<00:27,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 26: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [03:11<00:20,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 21: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [03:17<00:16,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 18: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [03:18<00:08,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 29: Digest length: 20 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [03:29<00:06,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 30: Digest length: 19 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [06:00<00:00, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 5: Digest length: 1561 characters\n",
      "\n",
      "Processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "fb337cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:10:39.997596Z",
     "start_time": "2025-10-12T14:10:39.944877Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "output_filename = 'pdf_extracted_text_with_digests.csv'\n",
    "df.to_csv(output_filename, index=False)\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "78dd0f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T14:11:27.846446Z",
     "start_time": "2025-10-12T14:11:27.778286Z"
    }
   },
   "source": [
    "print(\"DIGEST ANALYSIS for\", model_name)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total digests generated: {df[digest_col_name].notna().sum()}\")\n",
    "\n",
    "references_found = df[df[digest_col_name].str.contains('No references found', na=False)].shape[0]\n",
    "references_not_found = df[df[digest_col_name].notna() & ~df[digest_col_name].str.contains('No references found', na=False)].shape[0]\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Reference Analysis:\")\n",
    "print(f\"  â€¢ References found: {references_not_found}\")\n",
    "print(f\"  â€¢ No references found: {references_found}\")\n",
    "print(f\"  â€¢ Success rate: {references_not_found/(references_not_found + references_found)*100:.1f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š DIGEST ANALYSIS\n",
      "==================================================\n",
      "Total digests generated: 30\n",
      "Unique digest responses: 13\n",
      "\n",
      "ðŸ“ˆ Reference Analysis:\n",
      "  â€¢ References found: 9\n",
      "  â€¢ No references found: 21\n",
      "  â€¢ Success rate: 30.0%\n",
      "\n",
      "ðŸ” Examples of Found References:\n",
      "\n",
      "Example 1:\n",
      "  Row 0: No title...\n",
      "  Digest: Based on the provided thesis text, **no references to \"Exploring ChatGPT and its impact on society MA Haque, S Li\"** are found. The excerpt includes the abstract, acknowledgments, table of contents, a...\n",
      "\n",
      "Example 2:\n",
      "  Row 1: No title...\n",
      "  Digest: However, some previous studies also identify challenges, such as the risk of biased information and excessive reliance on technology (Basha, 2024; Haque & Li, 2024; Zhai et al., 2024)....\n",
      "\n",
      "Example 3:\n",
      "  Row 5: No title...\n",
      "  Digest: The article references the source \"Exploring ChatGPT and its impact on society MA Haque, S Li\" in the following section:\n",
      "\n",
      "**Section 1: Einleitung**  \n",
      "\"Allerdings gab es auch FÃ¤lle, in denen die Antwor...\n",
      "\n",
      "âŒ Examples of No References Found:\n",
      "\n",
      "Example 1:\n",
      "  Row 2: No title...\n",
      "\n",
      "Example 2:\n",
      "  Row 3: No title...\n",
      "\n",
      "Example 3:\n",
      "  Row 4: No title...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[35]\u001B[39m\u001B[32m, line 48\u001B[39m\n\u001B[32m     37\u001B[39m summary_stats = {\n\u001B[32m     38\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mtotal_rows\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28mlen\u001B[39m(df),\n\u001B[32m     39\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mprocessed_rows\u001B[39m\u001B[33m'\u001B[39m: df[\u001B[33m'\u001B[39m\u001B[33mdigest\u001B[39m\u001B[33m'\u001B[39m].notna().sum(),\n\u001B[32m   (...)\u001B[39m\u001B[32m     44\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mmodel_used\u001B[39m\u001B[33m'\u001B[39m: model_name\n\u001B[32m     45\u001B[39m }\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mdigest_summary.json\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mw\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m     \u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_stats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindent\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mðŸ“‹ Summary statistics saved to \u001B[39m\u001B[33m'\u001B[39m\u001B[33mdigest_summary.json\u001B[39m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     51\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mâœ… All processing complete!\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.12/json/__init__.py:179\u001B[39m, in \u001B[36mdump\u001B[39m\u001B[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001B[39m\n\u001B[32m    173\u001B[39m     iterable = \u001B[38;5;28mcls\u001B[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001B[32m    174\u001B[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001B[32m    175\u001B[39m         separators=separators,\n\u001B[32m    176\u001B[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001B[32m    177\u001B[39m \u001B[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001B[39;00m\n\u001B[32m    178\u001B[39m \u001B[38;5;66;03m# a debuggability cost\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.12/json/encoder.py:432\u001B[39m, in \u001B[36m_make_iterencode.<locals>._iterencode\u001B[39m\u001B[34m(o, _current_indent_level)\u001B[39m\n\u001B[32m    430\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_list(o, _current_indent_level)\n\u001B[32m    431\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(o, \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m432\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_dict(o, _current_indent_level)\n\u001B[32m    433\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    434\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m markers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.12/json/encoder.py:406\u001B[39m, in \u001B[36m_make_iterencode.<locals>._iterencode_dict\u001B[39m\u001B[34m(dct, _current_indent_level)\u001B[39m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    405\u001B[39m             chunks = _iterencode(value, _current_indent_level)\n\u001B[32m--> \u001B[39m\u001B[32m406\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m chunks\n\u001B[32m    407\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m newline_indent \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    408\u001B[39m     _current_indent_level -= \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.12/json/encoder.py:439\u001B[39m, in \u001B[36m_make_iterencode.<locals>._iterencode\u001B[39m\u001B[34m(o, _current_indent_level)\u001B[39m\n\u001B[32m    437\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCircular reference detected\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    438\u001B[39m     markers[markerid] = o\n\u001B[32m--> \u001B[39m\u001B[32m439\u001B[39m o = \u001B[43m_default\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    440\u001B[39m \u001B[38;5;28;01myield from\u001B[39;00m _iterencode(o, _current_indent_level)\n\u001B[32m    441\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m markers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.12/json/encoder.py:180\u001B[39m, in \u001B[36mJSONEncoder.default\u001B[39m\u001B[34m(self, o)\u001B[39m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdefault\u001B[39m(\u001B[38;5;28mself\u001B[39m, o):\n\u001B[32m    162\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Implement this method in a subclass such that it returns\u001B[39;00m\n\u001B[32m    163\u001B[39m \u001B[33;03m    a serializable object for ``o``, or calls the base implementation\u001B[39;00m\n\u001B[32m    164\u001B[39m \u001B[33;03m    (to raise a ``TypeError``).\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \n\u001B[32m    179\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m180\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mObject of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mo.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    181\u001B[39m                     \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mis not JSON serializable\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mTypeError\u001B[39m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63ff74b49d53af1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
